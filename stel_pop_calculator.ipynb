{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellar population fit by ppxf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:17.992083Z",
     "start_time": "2024-11-28T17:44:17.989177Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from os.path import basename\n",
    "from copy import copy\n",
    "\n",
    "from ppxf.ppxf import ppxf\n",
    "import ppxf.ppxf_util as util\n",
    "import ppxf.sps_util as lib\n",
    "\n",
    "# These need to be obtained from somewhere\n",
    "# from nedcalc_class import NedCalculator\n",
    "\n",
    "from der_snr import DER_SNR\n",
    "\n",
    "from ned import NedCalculator\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create necessary functions"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.003247Z",
     "start_time": "2024-11-28T17:44:18.000310Z"
    }
   },
   "source": [
    "def bootstrap_residuals(model, resid, wild=True):\n",
    "    \"\"\"\n",
    "    https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Resampling_residuals\n",
    "    https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Wild_bootstrap\n",
    "\n",
    "    Davidson & Flachaire (2008) eq.(12) gives the recommended form\n",
    "    of the wild bootstrapping probability used here.\n",
    "\n",
    "    https://doi.org/10.1016/j.jeconom.2008.08.003\n",
    "\n",
    "    :param spec: model (e.g. best fitting spectrum)\n",
    "    :param res: residuals (best_fit - observed)\n",
    "    :param wild: use wild bootstrap to allow for variable errors\n",
    "    :return: new model with bootstrapped residuals\n",
    "\n",
    "    \"\"\"\n",
    "    if wild:    # Wild Bootstrapping: generates -resid or resid with prob=1/2\n",
    "        eps = resid*(2*np.random.randint(2, size=resid.size) - 1)\n",
    "    else:       # Standard Bootstrapping: random selection with repetition\n",
    "        eps = np.random.choice(resid, size=resid.size)\n",
    "\n",
    "    return model + eps"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.023537Z",
     "start_time": "2024-11-28T17:44:18.020256Z"
    }
   },
   "source": [
    "def read_fits_summary(fitsfile):\n",
    "    \n",
    "    hdu = fits.open(fitsfile)\n",
    "    \n",
    "    age_grid = hdu['age_grid'].data\n",
    "    weights = hdu['pp_weights'].data.reshape(hdu['reg_dim'].data)\n",
    "    \n",
    "    name = hdu[0].header['name']\n",
    "    z = hdu[0].header['z']\n",
    "    hdu.close()\n",
    "    del hdu\n",
    "    \n",
    "    wei1 = weights.sum(axis=1)\n",
    "    wei1/=wei1.sum()\n",
    "    \n",
    "    wei1_rev = copy(wei1[::-1])\n",
    "    \n",
    "    ages = age_grid[:,0]\n",
    "    ages1 = (ages[-1]-ages)[::-1]+(ages[1]-ages[0])\n",
    "    \n",
    "    agesplot = np.concatenate([np.array([0.]),ages1])\n",
    "    weiplot = np.concatenate([np.array([0.]),np.cumsum(wei1_rev)])\n",
    "    \n",
    "    agesplot = np.concatenate([agesplot,np.array([agesplot[-1]+(agesplot[-1]-agesplot[-2])])])\n",
    "    weiplot = np.concatenate([weiplot,np.array([weiplot[-1]])])\n",
    "    \n",
    "    # nedcalc = NedCalculator([z])\n",
    "    nedcalc = NedCalculator(z)\n",
    "    univ_age = nedcalc.zage_Gyr\n",
    "    \n",
    "    agesplot = [a if a<univ_age else univ_age for a in agesplot]\n",
    "    \n",
    "    return name,z,agesplot,weiplot,univ_age\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.042441Z",
     "start_time": "2024-11-28T17:44:18.038739Z"
    }
   },
   "source": [
    "def plot_sfh(ax,fitsfile,col_line,legend_on=False):\n",
    "    name,z,agesplot,weiplot,univ_age = read_fits_summary(fitsfile)\n",
    "\n",
    "    ax.set_title(name,fontsize=18,weight='bold')\n",
    "    ax.set_xlim(0,13.5)\n",
    "    ax.set_ylim(-0.05,1.05)\n",
    "    ax.set_xlabel('Time since BB (Gyr)',fontsize=15)\n",
    "    ax.set_ylabel('Cumulative mass %',fontsize=15)\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='both',which='both',direction='in',labelsize=15)\n",
    "    \n",
    "    ax.axhline(0.75,color='gray',alpha=0.2)\n",
    "    ax.text(12,0.76,'75%',style='italic',color='gray')\n",
    "    ax.axhline(0.95,color='gray',alpha=0.2)\n",
    "    ax.text(12,0.96,'95%',style='italic',color='gray')\n",
    "    ax.axvline(3.,color='gray',alpha=0.2,linestyle='-.',linewidth=2.)\n",
    "    ax.axvline(univ_age,color='gray',linestyle='-.',linewidth=2.)\n",
    "    \n",
    "    ax.plot(agesplot,weiplot,color=col_line,linewidth=3.)\n",
    "    \n",
    "    ax.text(univ_age-0.1,0.,'today',color='gray',style='italic',rotation=90,horizontalalignment='right')\n",
    "    ax.text(2.9,0.,'z~2',style='italic',color='gray',rotation=90,horizontalalignment='right')\n",
    "    ax.set_xticks([0.,2.,4.,6.,8.,10.,12.])\n",
    "    \n",
    "    if legend_on==True:\n",
    "        ax.legend(frameon=False,bbox_to_anchor=(univ_age/ax.get_xlim()[1], -0.05),loc='lower right',prop={'size':12,'weight':'bold'},labelspacing=0.1,labelcolor='linecolor')\n",
    "        \n",
    "    return agesplot,weiplot"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.063061Z",
     "start_time": "2024-11-28T17:44:18.057139Z"
    }
   },
   "source": [
    "def line2p(p1,p2,x):\n",
    "    \n",
    "    x1,y1 = p1\n",
    "    x2,y2 = p2\n",
    "    \n",
    "    m = (y2-y1)/(x2-x1)\n",
    "    q = -(y2-y1)/(x2-x1)*x1+y1\n",
    "    \n",
    "    return m*x+q\n",
    "\n",
    "def line2p_rev(p1,p2,y):\n",
    "    \n",
    "    x1,y1 = p1\n",
    "    x2,y2 = p2\n",
    "    \n",
    "    return (y-y1)/(y2-y1)*(x2-x1)+x1 if y2!=y1 else x2\n",
    "    \n",
    "def get_values_from_sfh(univ_age,sfh_table,ycol):\n",
    "    '''\n",
    "    INPUTS:\n",
    "        univ_age: the age of the universe at the redshift of the galaxy in Gyr\n",
    "        sfh_table: the plotted sfh in the form of a pandas DataFrame. It needs to have a column named \"time\"\n",
    "        ycol: is the name of the column of the sfh_table we want to use in order to retrieve the different values we want to compute\n",
    "    \n",
    "    OUTPUTS:\n",
    "        y_z2: mass formed at redshift~2\n",
    "        x_075: time to form 75% of the mass (t_75)\n",
    "        x_090: time to form 90% of the mass (t_90)\n",
    "        x_100: time to form 100% of the mass (t_fin)\n",
    "        dor_90: Degree of Relicness using x_090\n",
    "        dor_100: : Degree of Relicness using x_100\n",
    "    '''\n",
    "    \n",
    "    tt = []\n",
    "    tt90 = []\n",
    "    tt100 = []\n",
    "    \n",
    "    ii=0\n",
    "    while sfh_table.iloc[ii][ycol]<0.75:\n",
    "        tt.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "        ii+=1\n",
    "    tt.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "    \n",
    "    yy = sfh_table.iloc[np.array(tt[-2:])[:,0]]\n",
    "    \n",
    "    xx = line2p_rev(yy[['time',ycol]].iloc[0].values,yy[['time',ycol]].iloc[1].values,0.75)\n",
    "    \n",
    "    ii=0\n",
    "    while sfh_table.iloc[ii][ycol]<0.9 :\n",
    "        tt90.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "        ii+=1\n",
    "    tt90.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "    \n",
    "    yy90 = sfh_table.iloc[np.array(tt90[-2:])[:,0]]\n",
    "    \n",
    "    xx90 =  line2p_rev(yy90[['time',ycol]].iloc[0].values,yy90[['time',ycol]].iloc[1].values,0.9)\n",
    "    \n",
    "    ii=0\n",
    "    while sfh_table.iloc[ii][ycol]<0.998 :\n",
    "        tt100.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "        ii+=1\n",
    "    tt100.append((ii,sfh_table.iloc[ii][ycol]))\n",
    "    \n",
    "    yy100 = sfh_table.iloc[np.array(tt100[-2:])[:,0]]\n",
    "    \n",
    "    xx100 =  line2p_rev(yy100[['time',ycol]].iloc[0].values,yy100[['time',ycol]].iloc[1].values,0.998)\n",
    "    \n",
    "    tt_rev = [(0,0)]\n",
    "    \n",
    "    for i in range(1,len(sfh_table['time'])):\n",
    "        \n",
    "        p1 = sfh_table['time'].iloc[i-1],sfh_table[ycol].iloc[i-1]\n",
    "        p2 = sfh_table['time'].iloc[i],sfh_table[ycol].iloc[i]\n",
    "        \n",
    "        xs = np.arange(sfh_table['time'].iloc[i-1],sfh_table['time'].iloc[i]+0.1,0.1)\n",
    "        ys = line2p(p1,p2,xs)\n",
    "\n",
    "                \n",
    "        for x,y in zip(xs,ys):\n",
    "            tt_rev.append((round(x,2),y))\n",
    "\n",
    "\n",
    "    tt_rev = np.array(tt_rev)\n",
    "\n",
    "    # this is the mass formed at redshift ~2\n",
    "    y_z2 = round(tt_rev[:,1][np.where(tt_rev[:,0]==2.90)[0]][0],5)\n",
    "    \n",
    "    # these are the times at 75%, 90%, and 100% formed mass\n",
    "    x_075 = round(xx,5)\n",
    "    x_090 = round(xx90,5)\n",
    "    x_100 = round(xx100,5)\n",
    "    \n",
    "    dor_90 = (y_z2+0.5/x_075+(0.7+(univ_age-x_090)/univ_age))/3\n",
    "    dor_100 = (y_z2+0.5/x_075+(0.7+(univ_age-x_100)/univ_age))/3\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_z2,x_075,x_090,x_100,dor_90,dor_100"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the shortlist csv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.080999Z",
     "start_time": "2024-11-28T17:44:18.078724Z"
    }
   },
   "source": [
    "# The catalogue with all the galaxies\n",
    "# df_dor = pd.read_csv('/Users/johnmills/Summer project/DoR_fit/ppxf_stel_pop_dor_test.csv')\n",
    "# df_dor = pd.read_csv(\"data/E-INSPIRE_I_master_catalogue.csv\")\n",
    "# df_dor.head()\n",
    "\n",
    "clustering_methods = {\n",
    "    'DoR': ['DoR_0', 'DoR_1', 'DoR_2'],\n",
    "    'KMeans': ['KMeans_0', 'KMeans_1', 'KMeans_2'],\n",
    "    'GMM': ['GMM_0', 'GMM_1', 'GMM_2'],\n",
    "    'Hierarchical': ['Hierarchical_0', 'Hierarchical_1', 'Hierarchical_2']\n",
    "}\n",
    "\n",
    "file_names = []\n",
    "method = 'DoR' # change for each method!\n",
    "files_list = clustering_methods[method]\n",
    "for file in files_list:\n",
    "    file = \"output_fits/stacked_\"+file+\".fits\"\n",
    "    file_names.append(file)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over each row to fit the stellar population of each object"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:44:18.098777Z",
     "start_time": "2024-11-28T17:44:18.096342Z"
    }
   },
   "source": [
    "tie_balmer = True\n",
    "limit_doublets = True\n",
    "\n",
    "c = 299792.458  # speed of light in km/s\n",
    "\n",
    "regul_err = 0.1 # Large regularization error\n",
    "\n",
    "vel = 0   # eq.(8) of Cappellari (2017)\n",
    "\n",
    "moments = [4, 2, 2]\n",
    "\n",
    "gas_reddening = 0 if tie_balmer else None\n",
    "\n",
    "logAges = []\n",
    "metals = []\n",
    "snrs = []\n",
    "\n",
    "nrand = 9\n",
    "col_line1 = 'black' # gdago: here you choose the color of the line        \n",
    "col_line2 = 'green' # gdago: here you choose the color of the line\n",
    "\n",
    "# Some lists to add into the catalogue later\n",
    "mass_fracs = []\n",
    "times_75 = []\n",
    "times_90 = []\n",
    "times_100 = []\n",
    "dors_100 = []\n",
    "univ_ages = []\n",
    "\n",
    "mass_fracsu = []\n",
    "times_75u = []\n",
    "times_90u = []\n",
    "times_100u = []\n",
    "dors_100u = []\n",
    "\n",
    "mass_fracsr = []\n",
    "times_75r = []\n",
    "times_90r = []\n",
    "times_100r = []\n",
    "dors_100r = []"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:48:30.585865Z",
     "start_time": "2024-11-28T17:48:28.275917Z"
    }
   },
   "source": [
    "# Loop over all the galaxies in the catalogue\n",
    "# for index, row in df_dor.iterrows():\n",
    "\n",
    "for i, filename in enumerate(file_names):\n",
    "\n",
    " ####################################  instead we read our output_fits files. \n",
    "    \"\"\"# The following lines find each object in the folder containing the fits files\n",
    "    plate = row['plate']\n",
    "    mjd = row['mjd']\n",
    "    fiberid = row['fiberid']\n",
    "    txt_name = '/spec-' + f'{plate:04}' + '-' + f'{mjd:05}' + '-' + f'{fiberid:04}' + '.fits'\n",
    "    #hdu = fits.open('/Users/johnmills/Summer project/alpha_calculator/fits_shortlist' + txt_name, ignore_missing_simple=True)\n",
    "    hdu = fits.open('fits_shortlist' + txt_name, ignore_missing_simple=True)\n",
    "\n",
    "    t = hdu['COADD'].data\n",
    "\n",
    "    galaxy = t['flux']/np.median(t['flux'])     # Normalize spectrum to avoid numerical issues\n",
    "    ln_lam_gal = t['loglam']*np.log(10)         # Convert lg --> ln\n",
    "    wave = np.exp(ln_lam_gal)\n",
    "\n",
    "    redshift = row['z']\n",
    "    sigma = row['velDisp_ppxf']\n",
    "    alpha = row['alpha']\"\"\"\n",
    " \n",
    "    hdu = fits.open(filename, ignore_missing_simple=True)\n",
    "    \n",
    "    t = hdu['COADD'].data\n",
    "    galaxy = t['flux']\n",
    "    wave = t['wave']\n",
    "    \n",
    "    galaxy = galaxy[(wave > 3600) & (wave < 6500)]\n",
    "    wave = wave[(wave > 3600) & (wave < 6500)]\n",
    "    \n",
    "    sigma = t['sigma'][0]\n",
    "    alpha = t['ALPHA'][0]  # array of the average alpha (repeated many times for formatting sake)\n",
    "    # SWAP OUT FOR WHATEVER JOHN CALCULATES!!!\n",
    "    redshift = 0\n",
    "##########################################\n",
    "    \n",
    "    if alpha < 0:\n",
    "        alpha = '0'\n",
    "    elif alpha > 0.4:\n",
    "        alpha = '4'\n",
    "    else:\n",
    "        alpha = str(int(alpha*10))\n",
    "\n",
    "    # wave = wave/(1 + redshift)  # Compute wave in the galaxy rest frame\n",
    "    # Restrict wavelength range\n",
    "    # galaxy = galaxy[(wave > 3600) & (wave < 6500)]\n",
    "    # wave = wave[(wave > 3600) & (wave < 6500)]\n",
    "\n",
    "    snr = DER_SNR(galaxy) # Compute SNR\n",
    "    snrs.append(snr)\n",
    "    print(snrs)\n",
    "    wave *= np.median(util.vac_to_air(wave)/wave)\n",
    "\n",
    "    noise = np.full_like(galaxy, 0.0163)  # Assume constant noise per pixel here\n",
    "\n",
    "    d_ln_lam = np.log(wave[-1]/wave[0])/(wave.size - 1)  # Average ln_lam step\n",
    "    velscale = c*d_ln_lam                   # eq. (8) of Cappellari (2017)\n",
    "    FWHM_gal = 2.76/(1+redshift)  # SDSS has an approximate instrumental resolution FWHM of 2.76A.\n",
    "    \n",
    "    # Load the SSP models \n",
    "    ssp_file = f'MILES_SSP/alpha{alpha}.npz'\n",
    "    sps = lib.sps_lib(ssp_file, velscale, FWHM_gal, age_range=[0, NedCalculator(redshift).zage_Gyr], metal_range=[-2, 0.5])\n",
    "\n",
    "    reg_dim = sps.templates.shape[1:]\n",
    "    stars_templates = sps.templates.reshape(sps.templates.shape[0], -1)\n",
    "\n",
    "    lam_range_gal = np.array([np.min(wave), np.max(wave)])\n",
    "\n",
    "    gas_templates, gas_names, line_wave = util.emission_lines(\n",
    "        sps.ln_lam_temp, lam_range_gal, FWHM_gal, tie_balmer=tie_balmer,\n",
    "        limit_doublets=limit_doublets)\n",
    "    \n",
    "    templates = np.column_stack([stars_templates, gas_templates])\n",
    "\n",
    "    # start = [vel, sigma]     # (km/s), starting guess for [V, sigma]\n",
    "    start = [vel, sigma]\n",
    " \n",
    "    n_temps = stars_templates.shape[1]\n",
    "    n_forbidden = np.sum([\"[\" in a for a in gas_names])  # forbidden lines contain \"[*]\"\n",
    "    n_balmer = len(gas_names) - n_forbidden\n",
    "\n",
    "    component = [0]*n_temps + [1]*n_balmer + [2]*n_forbidden\n",
    "    gas_component = np.array(component) > 0  # gas_component=True for gas templates\n",
    "\n",
    "    start = [start, start, start]\n",
    "\n",
    "    # First run is just to compute a good estimate of the noise (it isn't used in the final fit)\n",
    "    pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "            degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "            regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "            gas_component=gas_component, gas_names=gas_names,\n",
    "            gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "    noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "    pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "                degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "                regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "                gas_component=gas_component, gas_names=gas_names,\n",
    "                gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "    \n",
    "    weights = pp.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "    weights = weights.reshape(reg_dim)/weights.sum()    # Normalized\n",
    "\n",
    "    mean_age = sps.mean_age_metal(weights, quiet=True)\n",
    "\n",
    "    hdu_wei = fits.ImageHDU(data=weights,name='pp_weights') # save the grid before reshaping the weights\n",
    "    hdu_regdim = fits.ImageHDU(data=reg_dim,name='reg_dim')\n",
    "    hdu_age = fits.ImageHDU(data=sps.age_grid,name='age_grid')\n",
    "    hdu_metal = fits.ImageHDU(data=sps.metal_grid,name='metal_grid')\n",
    "    bestfit = fits.ImageHDU(data=pp.bestfit,name='bestfit_spectrum')\n",
    "    lam = fits.ImageHDU(data=wave,name='wavelength')\n",
    "    orig = fits.ImageHDU(data=galaxy,name='original_spectrum')\n",
    "    gas = fits.ImageHDU(data=pp.gas_bestfit,name='gas_bestfit')\n",
    "\n",
    "    #Store the results in a way that is suitable for Peppe's SFH plotting\n",
    "    \n",
    "    #name = row['sexa_id'] #This is just the ID\n",
    "    name = f\"/\"+filename\n",
    "    z_orig = redshift # This should be the original redshift of each galaxy\n",
    "    # Write outputs in fits files\n",
    "    hdr = fits.Header()\n",
    "    #hdr['HIERARCH SDSS_ID'] = row['objid']\n",
    "    hdr['HIERARCH NAME'] = name\n",
    "    hdr['HIERARCH z'] = z_orig\n",
    "    hdr['HIERARCH mean_age_unr'] = mean_age[0]\n",
    "    hdr['HIERARCH mean_metal_unr'] = mean_age[1]\n",
    "    hdr['HIERARCH Mg/Fe'] = alpha           \n",
    "    #hdr['HIERARCH velDisp'] = row['velDisp_ppxf']\n",
    "    hdr['HIERARCH SNR'] = snr\n",
    "    primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "    hdulist = [primary_hdu, hdu_wei, hdu_regdim, hdu_age, hdu_metal, bestfit, lam, orig, gas]\n",
    "    hdulis = fits.HDUList(hdulist)\n",
    "    savepath = './ppxf_fits_test2/'\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)\n",
    "     \n",
    "    hdulis.writeto(savepath+name+'_ppxfout_UNR.fits',overwrite=True)\n",
    "\n",
    "\n",
    "    # Bootstrapping\n",
    "    bestfit0 = pp.bestfit.copy()\n",
    "    resid = galaxy - bestfit0\n",
    "    start = pp.sol.copy()\n",
    "\n",
    "    np.random.seed(123)\n",
    "\n",
    "    weights_array = np.empty((nrand, pp.weights.size))\n",
    "    for j in range(nrand):\n",
    "\n",
    "        galaxy1 = bootstrap_residuals(bestfit0, resid)\n",
    "\n",
    "        pp = ppxf(templates, galaxy1, noise, velscale, start, moments=moments,\n",
    "                degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "                component=component,\n",
    "                gas_component=gas_component, gas_names=gas_names,\n",
    "                gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "        noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "        pp = ppxf(templates, galaxy1, noise, velscale, start, moments=moments,\n",
    "                degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "                component=component,\n",
    "                gas_component=gas_component, gas_names=gas_names,\n",
    "                gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "\n",
    "        weights_array[j] = pp.weights\n",
    "\n",
    "        weights = pp.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "        weights = weights.reshape(reg_dim)/weights.sum()    # Normalized\n",
    "\n",
    "    pp.weights = weights_array.sum(0)\n",
    "    weights_err = weights_array.std(0)\n",
    "\n",
    "    weights = pp.weights[~gas_component]  # E+fxclude weights of the gas templates\n",
    "    weights = weights.reshape(reg_dim)/weights.sum()  # Normalized\n",
    "    \n",
    "    mean_age = sps.mean_age_metal(weights, quiet=True)\n",
    "    sps.mean_age_metal(weights, quiet=True);\n",
    "    logAges.append(mean_age[0])\n",
    "    metals.append(mean_age[1])\n",
    "\n",
    "    hdu_wei = fits.ImageHDU(data=weights,name='pp_weights') # save the grid before reshaping the weights\n",
    "    hdu_regdim = fits.ImageHDU(data=reg_dim,name='reg_dim')\n",
    "    hdu_age = fits.ImageHDU(data=sps.age_grid,name='age_grid')\n",
    "    hdu_metal = fits.ImageHDU(data=sps.metal_grid,name='metal_grid')\n",
    "    bestfit = fits.ImageHDU(data=pp.bestfit,name='bestfit_spectrum')\n",
    "    lam = fits.ImageHDU(data=wave,name='wavelength')\n",
    "    orig = fits.ImageHDU(data=galaxy,name='original_spectrum')\n",
    "    gas = fits.ImageHDU(data=pp.gas_bestfit,name='gas_bestfit')\n",
    "\n",
    "    # Write outputs in fits files\n",
    "    hdr = fits.Header()\n",
    "    #hdr['HIERARCH SDSS_ID'] = row['objid']\n",
    "    hdr['HIERARCH NAME'] = name\n",
    "    hdr['HIERARCH z'] = z_orig\n",
    "    hdr['HIERARCH mean_age_unr'] = mean_age[0]\n",
    "    hdr['HIERARCH mean_metal_unr'] = mean_age[1]\n",
    "    hdr['HIERARCH Mg/Fe'] = alpha\n",
    "    #hdr['HIERARCH velDisp'] = row['velDisp_ppxf']\n",
    "    hdr['HIERARCH SNR'] = snr\n",
    "    primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "    hdulist = [primary_hdu, hdu_wei, hdu_regdim, hdu_age, hdu_metal, bestfit, lam, orig, gas]\n",
    "    hdulis = fits.HDUList(hdulist)\n",
    "    hdulis.writeto(savepath+name+'_ppxfout_REGUL.fits',overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Plotting SFHs for each galaxy (but this section not needed for fitting stel pop parameters)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax1 = plt.subplot(1,1,1)\n",
    "\n",
    "    ppxfout_file_unr = savepath + name + '_ppxfout_UNR.fits'\n",
    "    ppxfout_file = savepath + name + '_ppxfout_REGUL.fits'\n",
    "\n",
    "    agesplot,weiplot = plot_sfh(ax1,ppxfout_file_unr,col_line1,legend_on=False) \n",
    "    agesplot,weiplot = plot_sfh(ax1,ppxfout_file,col_line2,legend_on=False)\n",
    "\n",
    "    savepath = './sfh_plots_test2/'\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "    plt.savefig(savepath+basename(ppxfout_file).replace('.fits','.pdf'),dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "    ## Computing DoR values (also not needed for fitting stel pop parameters)\n",
    "\n",
    "    name1,z1,agesplot1,weiplot1,univ_age1 = read_fits_summary(ppxfout_file_unr)\n",
    "    name2,z2,agesplot2,weiplot2,univ_age2 = read_fits_summary(ppxfout_file)\n",
    "    df_out = pd.DataFrame({'time':agesplot1, 'regul0':weiplot1, 'regul_max':weiplot2})\n",
    "    y_z2u,x_075u,x_090u,x_100u,dor_90u,dor_100u = get_values_from_sfh(univ_age1,df_out,\"regul0\")\n",
    "    y_z2r,x_075r,x_090r,x_100r,dor_90r,dor_100r = get_values_from_sfh(univ_age2,df_out,\"regul_max\")\n",
    "\n",
    "    mass_fracsu.append(y_z2u)\n",
    "    times_75u.append(x_075u)\n",
    "    times_90u.append(x_090u)\n",
    "    times_100u.append(x_100u)\n",
    "    dors_100u.append(dor_100u)\n",
    "\n",
    "    mass_fracsr.append(y_z2r)\n",
    "    times_75r.append(x_075r)\n",
    "    times_90r.append(x_090r)\n",
    "    times_100r.append(x_100r)\n",
    "    dors_100r.append(dor_100r)\n",
    "\n",
    "    y_z2 = min(y_z2u,y_z2r)\n",
    "    x_075 = max(x_075u,x_075r)\n",
    "    x_090 = max(x_090u,x_090r)\n",
    "    x_100 = max(x_100u,x_100r)\n",
    "    dor_100 = (y_z2+0.5/x_075+(0.7+(univ_age1-x_100))/univ_age1)/3\n",
    "\n",
    "    mass_fracs.append(y_z2)\n",
    "    times_75.append(x_075)\n",
    "    times_90.append(x_090)\n",
    "    times_100.append(x_100)\n",
    "    dors_100.append(dor_100)\n",
    "    univ_ages.append(univ_age1)\n",
    "        \n",
    "    print(f'{method} cluster {i} done')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1092.1147079476093, 3083.023262647888, 808.968025923069, 1092.1147079476093]\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save everything"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:48:11.869475Z",
     "start_time": "2024-11-28T17:37:33.707070Z"
    }
   },
   "source": [
    "df_dor = pd.DataFrame()\n",
    "df_dor['logAge'] = logAges\n",
    "df_dor['[M/H]'] = metals\n",
    "df_dor['SNR'] = snrs\n",
    "\n",
    "df_dor['mass_frac'] = mass_fracs\n",
    "df_dor['time_75'] = times_75\n",
    "df_dor['time_90'] = times_90\n",
    "df_dor['time_100'] = times_100\n",
    "df_dor['dor_100'] = dors_100\n",
    "df_dor['univ_age'] = univ_ages\n",
    "   \n",
    "df_dor['mass_frac_reg'] = mass_fracsr\n",
    "df_dor['time_75_reg'] = times_75r\n",
    "df_dor['time_90_reg'] = times_90r\n",
    "df_dor['time_100_reg'] = times_100r\n",
    "df_dor['dor_100_reg'] = dors_100r\n",
    "\n",
    "df_dor['mass_frac_unr'] = mass_fracsu\n",
    "df_dor['time_75_unr'] = times_75u\n",
    "df_dor['time_90_unr'] = times_90u\n",
    "df_dor['time_100_unr'] = times_100u\n",
    "df_dor['dor_100_unr'] = dors_100u\n",
    "\n",
    "df_dor.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      logAge     [M/H]          SNR  mass_frac  time_75   time_90  time_100  \\\n",
       "0  10.085804  0.342253  1092.114708    0.95838  0.82026   1.13965   3.47750   \n",
       "1  10.074578  0.298722  3083.023263    0.97521  1.31858   2.05453  12.23949   \n",
       "2   9.863940  0.228259   808.968026    0.67039  4.29502  11.30415  12.06280   \n",
       "\n",
       "    dor_100   univ_age  mass_frac_reg  time_75_reg  time_90_reg  time_100_reg  \\\n",
       "0  0.782298  12.565039        0.95838      0.67293      0.94229       3.47750   \n",
       "1  0.478675  12.565039        0.97521      0.78973      2.05453      12.22371   \n",
       "2  0.294162  12.565039        0.70803      4.29502     11.24176      12.06280   \n",
       "\n",
       "   dor_100_reg  mass_frac_unr  time_75_unr  time_90_unr  time_100_unr  \\\n",
       "0     1.041546        1.00000      0.82026      1.13965       1.90643   \n",
       "1     0.778501        0.98040      1.31858      1.98483      12.23949   \n",
       "2     0.521472        0.67039      3.72330     11.30415      11.97461   \n",
       "\n",
       "   dor_100_unr  \n",
       "0     1.052613  \n",
       "1     0.695168  \n",
       "2     0.517223  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logAge</th>\n",
       "      <th>[M/H]</th>\n",
       "      <th>SNR</th>\n",
       "      <th>mass_frac</th>\n",
       "      <th>time_75</th>\n",
       "      <th>time_90</th>\n",
       "      <th>time_100</th>\n",
       "      <th>dor_100</th>\n",
       "      <th>univ_age</th>\n",
       "      <th>mass_frac_reg</th>\n",
       "      <th>time_75_reg</th>\n",
       "      <th>time_90_reg</th>\n",
       "      <th>time_100_reg</th>\n",
       "      <th>dor_100_reg</th>\n",
       "      <th>mass_frac_unr</th>\n",
       "      <th>time_75_unr</th>\n",
       "      <th>time_90_unr</th>\n",
       "      <th>time_100_unr</th>\n",
       "      <th>dor_100_unr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.085804</td>\n",
       "      <td>0.342253</td>\n",
       "      <td>1092.114708</td>\n",
       "      <td>0.95838</td>\n",
       "      <td>0.82026</td>\n",
       "      <td>1.13965</td>\n",
       "      <td>3.47750</td>\n",
       "      <td>0.782298</td>\n",
       "      <td>12.565039</td>\n",
       "      <td>0.95838</td>\n",
       "      <td>0.67293</td>\n",
       "      <td>0.94229</td>\n",
       "      <td>3.47750</td>\n",
       "      <td>1.041546</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.82026</td>\n",
       "      <td>1.13965</td>\n",
       "      <td>1.90643</td>\n",
       "      <td>1.052613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.074578</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>3083.023263</td>\n",
       "      <td>0.97521</td>\n",
       "      <td>1.31858</td>\n",
       "      <td>2.05453</td>\n",
       "      <td>12.23949</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>12.565039</td>\n",
       "      <td>0.97521</td>\n",
       "      <td>0.78973</td>\n",
       "      <td>2.05453</td>\n",
       "      <td>12.22371</td>\n",
       "      <td>0.778501</td>\n",
       "      <td>0.98040</td>\n",
       "      <td>1.31858</td>\n",
       "      <td>1.98483</td>\n",
       "      <td>12.23949</td>\n",
       "      <td>0.695168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.863940</td>\n",
       "      <td>0.228259</td>\n",
       "      <td>808.968026</td>\n",
       "      <td>0.67039</td>\n",
       "      <td>4.29502</td>\n",
       "      <td>11.30415</td>\n",
       "      <td>12.06280</td>\n",
       "      <td>0.294162</td>\n",
       "      <td>12.565039</td>\n",
       "      <td>0.70803</td>\n",
       "      <td>4.29502</td>\n",
       "      <td>11.24176</td>\n",
       "      <td>12.06280</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.67039</td>\n",
       "      <td>3.72330</td>\n",
       "      <td>11.30415</td>\n",
       "      <td>11.97461</td>\n",
       "      <td>0.517223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:48:11.870955Z",
     "start_time": "2024-11-28T17:37:33.776860Z"
    }
   },
   "source": "df_dor.to_csv(f'CATALOGUE_{method}.csv', index=False)",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute everything for alpha/Fe±0.1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:48:11.871158Z",
     "start_time": "2024-11-28T17:37:33.796282Z"
    }
   },
   "source": [
    "tie_balmer = True\n",
    "limit_doublets = True\n",
    "\n",
    "c = 299792.458  # speed of light in km/s\n",
    "\n",
    "regul_err = 0.1 # Large regularization error\n",
    "\n",
    "vel = 0   # eq.(8) of Cappellari (2017)\n",
    "\n",
    "moments = [4, 2, 2]\n",
    "\n",
    "gas_reddening = 0 if tie_balmer else None\n",
    "\n",
    "logAges = []\n",
    "metals = []\n",
    "snrs = []"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:48:11.871269Z",
     "start_time": "2024-11-28T17:37:33.828555Z"
    }
   },
   "source": [
    "# Same logic as before but no bootstrapping\n",
    "for i, filename in enumerate(file_names):\n",
    " \n",
    "    hdu = fits.open(filename, ignore_missing_simple=True)\n",
    "    \n",
    "    t = hdu['COADD'].data\n",
    "    galaxy = t['flux']\n",
    "    wave = t['wave']\n",
    "    \n",
    "    galaxy = galaxy[(wave > 3600) & (wave < 6500)]\n",
    "    wave = wave[(wave > 3600) & (wave < 6500)]\n",
    "    \n",
    "    sigma = t['sigma'][0]\n",
    "    alpha_orig = t['alpha'][0]  # array of the average alpha (repeated many times for formatting sake)\n",
    "    redshift = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  wave = wave0/(1 + redshift)  # Compute wave in the galaxy rest frame    SHOULDNT BE NEEDED HERE ANYMORE\n",
    "    galaxy = galaxy[(wave > 3600) & (wave < 6500)]\n",
    "    wave = wave[(wave > 3600) & (wave < 6500)]\n",
    "\n",
    "    # # alpha + 0.1\n",
    "    if alpha_orig < 0.4:\n",
    "        alpha = alpha_orig + 0.1\n",
    "\n",
    "        # if alpha_orig == 0 and row['alpha_flag'] == -1:   UNSURE WHAT ALPHA FLAG IS??\n",
    "            # alpha = 0.4\n",
    "\n",
    "        alpha = str(int(alpha*10))\n",
    "\n",
    "        snr = DER_SNR(galaxy)\n",
    "        snrs.append(snr)\n",
    "\n",
    "        wave *= np.median(util.vac_to_air(wave)/wave)\n",
    "\n",
    "        noise = np.full_like(galaxy, 0.0163)  # Assume constant noise per pixel here\n",
    "\n",
    "        d_ln_lam = np.log(wave[-1]/wave[0])/(wave.size - 1)  # Average ln_lam step\n",
    "        velscale = c*d_ln_lam                   # eq. (8) of Cappellari (2017)\n",
    "        FWHM_gal = 2.76/(1+redshift)  # SDSS has an approximate instrumental resolution FWHM of 2.76A.\n",
    "\n",
    "        ssp_file = f'MILES_SSP/alpha{alpha}.npz'\n",
    "        sps = lib.sps_lib(ssp_file, velscale, FWHM_gal, age_range=[0, NedCalculator(redshift).zage_Gyr], metal_range=[-2, 0.5])\n",
    "\n",
    "        reg_dim = sps.templates.shape[1:]\n",
    "        stars_templates = sps.templates.reshape(sps.templates.shape[0], -1)\n",
    "\n",
    "        lam_range_gal = np.array([np.min(wave), np.max(wave)])\n",
    "\n",
    "        gas_templates, gas_names, line_wave = util.emission_lines(\n",
    "            sps.ln_lam_temp, lam_range_gal, FWHM_gal, tie_balmer=tie_balmer,\n",
    "            limit_doublets=limit_doublets)\n",
    "        \n",
    "        templates = np.column_stack([stars_templates, gas_templates])\n",
    "\n",
    "        start = [vel, sigma]     # (km/s), starting guess for [V, sigma]\n",
    "\n",
    "        n_temps = stars_templates.shape[1]\n",
    "        n_forbidden = np.sum([\"[\" in a for a in gas_names])  # forbidden lines contain \"[*]\"\n",
    "        n_balmer = len(gas_names) - n_forbidden\n",
    "\n",
    "        component = [0]*n_temps + [1]*n_balmer + [2]*n_forbidden\n",
    "        gas_component = np.array(component) > 0  # gas_component=True for gas templates\n",
    "\n",
    "        start = [start, start, start]\n",
    "        \n",
    "\n",
    "        pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "            degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "            regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "            gas_component=gas_component, gas_names=gas_names,\n",
    "            gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "        noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "        pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "                    degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "                    regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "                    gas_component=gas_component, gas_names=gas_names,\n",
    "                    gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "        \n",
    "        weights = pp.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "        weights = weights.reshape(reg_dim)/weights.sum()    # Normalized\n",
    "\n",
    "        mean_age = sps.mean_age_metal(weights, quiet=True)\n",
    "\n",
    "        hdu_wei = fits.ImageHDU(data=weights,name='pp_weights') # save the grid before reshaping the weights\n",
    "        hdu_regdim = fits.ImageHDU(data=reg_dim,name='reg_dim')\n",
    "        hdu_age = fits.ImageHDU(data=sps.age_grid,name='age_grid')\n",
    "        hdu_metal = fits.ImageHDU(data=sps.metal_grid,name='metal_grid')\n",
    "        bestfit = fits.ImageHDU(data=pp.bestfit,name='bestfit_spectrum')\n",
    "        lam = fits.ImageHDU(data=wave,name='wavelength')\n",
    "        orig = fits.ImageHDU(data=galaxy,name='original_spectrum')\n",
    "        gas = fits.ImageHDU(data=pp.gas_bestfit,name='gas_bestfit')\n",
    "\n",
    "        #Store the results in a way that is suitable for Peppe's SFH plotting\n",
    "        # name = row['sexa_id'] #This is just the ID\n",
    "        name = f\"/\"+filename\n",
    "        z_orig = redshift # This should be the original redshift of each galaxy\n",
    "        # Write outputs in fits files\n",
    "        hdr = fits.Header()\n",
    "        # hdr['HIERARCH SDSS_ID'] = row['objid']\n",
    "        hdr['HIERARCH NAME'] = name\n",
    "        hdr['HIERARCH z'] = z_orig\n",
    "        hdr['HIERARCH mean_age_unr'] = mean_age[0]\n",
    "        hdr['HIERARCH mean_metal_unr'] = mean_age[1]\n",
    "        hdr['HIERARCH Mg/Fe'] = t['ALPHA'][0]\n",
    "        # hdr['HIERARCH velDisp'] = row['velDisp_ppxf']\n",
    "        hdr['HIERARCH SNR'] = snr\n",
    "        primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "        hdulist = [primary_hdu, hdu_wei, hdu_regdim, hdu_age, hdu_metal, bestfit, lam, orig, gas]\n",
    "        hdulis = fits.HDUList(hdulist)\n",
    "        savepath = './ppxf_fits_test2/'\n",
    "        if not os.path.exists(savepath):\n",
    "            os.makedirs(savepath)\n",
    "        hdulis.writeto(savepath+name+'_ppxfout_plus.fits',overwrite=True)\n",
    "\n",
    "    # alpha - 0.1\n",
    "    if alpha_orig > 0:\n",
    "        alpha = alpha_orig - 0.1\n",
    "\n",
    "        #if alpha_orig == 0.4 and row['alpha_flag'] == 1:   # I am not sure what alpha flag is??\n",
    "         #   alpha = 0.\n",
    "\n",
    "        alpha = str(int(alpha*10))\n",
    "\n",
    "        snr = DER_SNR(galaxy)\n",
    "        snrs.append(snr)\n",
    "\n",
    "        wave *= np.median(util.vac_to_air(wave)/wave)\n",
    "\n",
    "        noise = np.full_like(galaxy, 0.0163)\n",
    "\n",
    "        d_ln_lam = np.log(wave[-1]/wave[0])/(wave.size - 1)\n",
    "        velscale = c*d_ln_lam\n",
    "        FWHM_gal = 2.76/(1+redshift)\n",
    "\n",
    "        filename = f'MILES_SSP/alpha{alpha}.npz'\n",
    "\n",
    "        sps = lib.sps_lib(filename, velscale, FWHM_gal, age_range=[0, NedCalculator(redshift).zage_Gyr], metal_range=[-2, 0.5])\n",
    "\n",
    "        reg_dim = sps.templates.shape[1:]\n",
    "        stars_templates = sps.templates.reshape(sps.templates.shape[0], -1)\n",
    "\n",
    "        lam_range_gal = np.array([np.min(wave), np.max(wave)])\n",
    "\n",
    "        gas_templates, gas_names, line_wave = util.emission_lines(\n",
    "            sps.ln_lam_temp, lam_range_gal, FWHM_gal, tie_balmer=tie_balmer,\n",
    "            limit_doublets=limit_doublets)\n",
    "        \n",
    "        templates = np.column_stack([stars_templates, gas_templates])\n",
    "\n",
    "        start = [vel, sigma]\n",
    "\n",
    "        n_temps = stars_templates.shape[1]\n",
    "        n_forbidden = np.sum([\"[\" in a for a in gas_names])\n",
    "        n_balmer = len(gas_names) - n_forbidden\n",
    "\n",
    "        component = [0]*n_temps + [1]*n_balmer + [2]*n_forbidden\n",
    "        gas_component = np.array(component) > 0\n",
    "\n",
    "        start = [start, start, start]\n",
    "\n",
    "        pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "            degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "            regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "            gas_component=gas_component, gas_names=gas_names,\n",
    "            gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "        noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "        pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "                    degree=-1, mdegree=8, lam=wave, lam_temp=sps.lam_temp,\n",
    "                    regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "                    gas_component=gas_component, gas_names=gas_names,\n",
    "                    gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "        \n",
    "        weights = pp.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "        weights = weights.reshape(reg_dim)/weights.sum()    # Normalized\n",
    "\n",
    "        mean_age = sps.mean_age_metal(weights, quiet=True)\n",
    "\n",
    "        hdu_wei = fits.ImageHDU(data=weights,name='pp_weights') # save the grid before reshaping the weights\n",
    "        hdu_regdim = fits.ImageHDU(data=reg_dim,name='reg_dim')\n",
    "        hdu_age = fits.ImageHDU(data=sps.age_grid,name='age_grid')\n",
    "        hdu_metal = fits.ImageHDU(data=sps.metal_grid,name='metal_grid')\n",
    "        bestfit = fits.ImageHDU(data=pp.bestfit,name='bestfit_spectrum')\n",
    "        lam = fits.ImageHDU(data=wave,name='wavelength')\n",
    "        orig = fits.ImageHDU(data=galaxy,name='original_spectrum')\n",
    "        gas = fits.ImageHDU(data=pp.gas_bestfit,name='gas_bestfit')\n",
    "\n",
    "        #Store the results in a way that is suitable for Peppe's SFH plotting\n",
    "        # name = row['sexa_id'] #This is just the ID\n",
    "        z_orig = redshift # This should be the original redshift of each galaxy\n",
    "        # Write outputs in fits files\n",
    "        hdr = fits.Header()\n",
    "        #hdr['HIERARCH SDSS_ID'] = row['objid']\n",
    "        hdr['HIERARCH NAME'] = name\n",
    "        hdr['HIERARCH z'] = z_orig\n",
    "        hdr['HIERARCH mean_age_unr'] = mean_age[0]\n",
    "        hdr['HIERARCH mean_metal_unr'] = mean_age[1]\n",
    "        hdr['HIERARCH Mg/Fe'] = t['ALPHA'][0]\n",
    "        #hdr['HIERARCH velDisp'] = row['velDisp_ppxf']\n",
    "        hdr['HIERARCH SNR'] = snr\n",
    "        primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "        hdulist = [primary_hdu, hdu_wei, hdu_regdim, hdu_age, hdu_metal, bestfit, lam, orig, gas]\n",
    "        hdulis = fits.HDUList(hdulist)\n",
    "        savepath = './ppxf_fits_test2/'\n",
    "        if not os.path.exists(savepath):\n",
    "            os.makedirs(savepath)\n",
    "        hdulis.writeto(savepath+name+'_ppxfout_minus.fits',overwrite=True)\n",
    "\n",
    "    print(f'Galaxy {i} done')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Galaxy 0 done\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Galaxy 1 done\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Emission lines included in gas templates:\n",
      "['Balmer' '[OII]3726_d1' '[OII]3726_d2' '[NeIII]3968' '[NeIII]3869'\n",
      " 'HeII4687' 'HeI5876' '[OIII]5007_d' '[OI]6300_d']\n",
      "Galaxy 2 done\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
